{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ad942c5-ae8e-4a17-9558-232d12904be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.1 (SDL 2.28.2, Python 3.11.0)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import ventilation_env \n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3645754-eaeb-4881-836f-15c8c26fb01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74e2e29d-393f-4e82-8b5e-e9ea6f544bf4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'TimeLimit' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m vent_env \u001b[38;5;241m=\u001b[39m gym\u001b[38;5;241m.\u001b[39mmake(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVentilation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m vect_env \u001b[38;5;241m=\u001b[39m \u001b[43mmake_vec_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvent_env\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/plantroom-rl-NMgLvuyx-py3.11/lib/python3.11/site-packages/stable_baselines3/common/env_util.py:125\u001b[0m, in \u001b[0;36mmake_vec_env\u001b[0;34m(env_id, n_envs, seed, start_index, monitor_dir, wrapper_class, env_kwargs, vec_env_cls, vec_env_kwargs, monitor_kwargs, wrapper_kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m vec_env_cls \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;66;03m# Default: use a DummyVecEnv\u001b[39;00m\n\u001b[1;32m    123\u001b[0m     vec_env_cls \u001b[38;5;241m=\u001b[39m DummyVecEnv\n\u001b[0;32m--> 125\u001b[0m vec_env \u001b[38;5;241m=\u001b[39m \u001b[43mvec_env_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmake_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstart_index\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_envs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mvec_env_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# Prepare the seeds for the first reset\u001b[39;00m\n\u001b[1;32m    127\u001b[0m vec_env\u001b[38;5;241m.\u001b[39mseed(seed)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/plantroom-rl-NMgLvuyx-py3.11/lib/python3.11/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:30\u001b[0m, in \u001b[0;36mDummyVecEnv.__init__\u001b[0;34m(self, env_fns)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, env_fns: List[Callable[[], gym\u001b[38;5;241m.\u001b[39mEnv]]):\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43m_patch_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43menv_fns\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m([\u001b[38;5;28mid\u001b[39m(env\u001b[38;5;241m.\u001b[39munwrapped) \u001b[38;5;28;01mfor\u001b[39;00m env \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs])) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs):\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     33\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou tried to create multiple environments, but the function to create them returned the same instance \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     34\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstead of creating different objects. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease read https://github.com/DLR-RM/stable-baselines3/issues/1151 for more information.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     40\u001b[0m         )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/plantroom-rl-NMgLvuyx-py3.11/lib/python3.11/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:30\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, env_fns: List[Callable[[], gym\u001b[38;5;241m.\u001b[39mEnv]]):\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs \u001b[38;5;241m=\u001b[39m [_patch_env(\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m fn \u001b[38;5;129;01min\u001b[39;00m env_fns]\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m([\u001b[38;5;28mid\u001b[39m(env\u001b[38;5;241m.\u001b[39munwrapped) \u001b[38;5;28;01mfor\u001b[39;00m env \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs])) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs):\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     33\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou tried to create multiple environments, but the function to create them returned the same instance \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     34\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstead of creating different objects. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease read https://github.com/DLR-RM/stable-baselines3/issues/1151 for more information.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     40\u001b[0m         )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/plantroom-rl-NMgLvuyx-py3.11/lib/python3.11/site-packages/stable_baselines3/common/env_util.py:98\u001b[0m, in \u001b[0;36mmake_vec_env.<locals>.make_env.<locals>._init\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m         env \u001b[38;5;241m=\u001b[39m gym\u001b[38;5;241m.\u001b[39mmake(env_id, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39menv_kwargs)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 98\u001b[0m     env \u001b[38;5;241m=\u001b[39m \u001b[43menv_id\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43menv_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;66;03m# Patch to support gym 0.21/0.26 and gymnasium\u001b[39;00m\n\u001b[1;32m    100\u001b[0m     env \u001b[38;5;241m=\u001b[39m _patch_env(env)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'TimeLimit' object is not callable"
     ]
    }
   ],
   "source": [
    "vent_env = gym.make(\"Ventilation\")\n",
    "vect_env = make_vec_env(vent_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d72f0b7-38fc-430e-8f24-9e056f92607a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m vent_env \u001b[38;5;241m=\u001b[39m gym\u001b[38;5;241m.\u001b[39mmake(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVentilation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m vent_model \u001b[38;5;241m=\u001b[39m \u001b[43mPPO\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMlpPolicy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvent_env\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m vent_model\u001b[38;5;241m.\u001b[39mlearn(total_timesteps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25000\u001b[39m)\n\u001b[1;32m      4\u001b[0m vent_model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mppo_ventilation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/plantroom-rl-NMgLvuyx-py3.11/lib/python3.11/site-packages/stable_baselines3/ppo/ppo.py:104\u001b[0m, in \u001b[0;36mPPO.__init__\u001b[0;34m(self, policy, env, learning_rate, n_steps, batch_size, n_epochs, gamma, gae_lambda, clip_range, clip_range_vf, normalize_advantage, ent_coef, vf_coef, max_grad_norm, use_sde, sde_sample_freq, target_kl, stats_window_size, tensorboard_log, policy_kwargs, verbose, seed, device, _init_setup_model)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     79\u001b[0m     policy: Union[\u001b[38;5;28mstr\u001b[39m, Type[ActorCriticPolicy]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    102\u001b[0m     _init_setup_model: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    103\u001b[0m ):\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgae_lambda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgae_lambda\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43ment_coef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ment_coef\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvf_coef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvf_coef\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_grad_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_grad_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_sde\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_sde\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43msde_sample_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msde_sample_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstats_window_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstats_window_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtensorboard_log\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensorboard_log\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_init_setup_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43msupported_action_spaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m            \u001b[49m\u001b[43mspaces\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBox\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m            \u001b[49m\u001b[43mspaces\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDiscrete\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m            \u001b[49m\u001b[43mspaces\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMultiDiscrete\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m            \u001b[49m\u001b[43mspaces\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMultiBinary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# Sanity check, otherwise it will lead to noisy gradient and NaN\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;66;03m# because of the advantage normalization\u001b[39;00m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m normalize_advantage:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/plantroom-rl-NMgLvuyx-py3.11/lib/python3.11/site-packages/stable_baselines3/common/on_policy_algorithm.py:81\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.__init__\u001b[0;34m(self, policy, env, learning_rate, n_steps, gamma, gae_lambda, ent_coef, vf_coef, max_grad_norm, use_sde, sde_sample_freq, stats_window_size, tensorboard_log, monitor_wrapper, policy_kwargs, verbose, seed, device, _init_setup_model, supported_action_spaces)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     60\u001b[0m     policy: Union[\u001b[38;5;28mstr\u001b[39m, Type[ActorCriticPolicy]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     79\u001b[0m     supported_action_spaces: Optional[Tuple[Type[spaces\u001b[38;5;241m.\u001b[39mSpace], \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     80\u001b[0m ):\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_sde\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_sde\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m        \u001b[49m\u001b[43msde_sample_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msde_sample_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m        \u001b[49m\u001b[43msupport_multi_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstats_window_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstats_window_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtensorboard_log\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensorboard_log\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m        \u001b[49m\u001b[43msupported_action_spaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msupported_action_spaces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_steps \u001b[38;5;241m=\u001b[39m n_steps\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m=\u001b[39m gamma\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/plantroom-rl-NMgLvuyx-py3.11/lib/python3.11/site-packages/stable_baselines3/common/base_class.py:169\u001b[0m, in \u001b[0;36mBaseAlgorithm.__init__\u001b[0;34m(self, policy, env, learning_rate, policy_kwargs, stats_window_size, tensorboard_log, verbose, device, support_multi_env, monitor_wrapper, seed, use_sde, sde_sample_freq, supported_action_spaces)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m env \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    168\u001b[0m     env \u001b[38;5;241m=\u001b[39m maybe_make_env(env, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n\u001b[0;32m--> 169\u001b[0m     env \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrap_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonitor_wrapper\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mobservation_space\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39maction_space\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/plantroom-rl-NMgLvuyx-py3.11/lib/python3.11/site-packages/stable_baselines3/common/base_class.py:223\u001b[0m, in \u001b[0;36mBaseAlgorithm._wrap_env\u001b[0;34m(env, verbose, monitor_wrapper)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrapping the env in a DummyVecEnv.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 223\u001b[0m     env \u001b[38;5;241m=\u001b[39m \u001b[43mDummyVecEnv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[list-item, return-value]\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# Make sure that dict-spaces are not nested (not supported)\u001b[39;00m\n\u001b[1;32m    226\u001b[0m check_for_nested_spaces(env\u001b[38;5;241m.\u001b[39mobservation_space)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/plantroom-rl-NMgLvuyx-py3.11/lib/python3.11/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:46\u001b[0m, in \u001b[0;36mDummyVecEnv.__init__\u001b[0;34m(self, env_fns)\u001b[0m\n\u001b[1;32m     43\u001b[0m obs_space \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mobservation_space\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys, shapes, dtypes \u001b[38;5;241m=\u001b[39m obs_space_info(obs_space)\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_obs \u001b[38;5;241m=\u001b[39m OrderedDict(\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_envs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mshapes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs,), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs,), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/plantroom-rl-NMgLvuyx-py3.11/lib/python3.11/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:46\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     43\u001b[0m obs_space \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mobservation_space\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys, shapes, dtypes \u001b[38;5;241m=\u001b[39m obs_space_info(obs_space)\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_obs \u001b[38;5;241m=\u001b[39m OrderedDict([(k, np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mtuple\u001b[39m(shapes[k])), dtype\u001b[38;5;241m=\u001b[39mdtypes[k])) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys])\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs,), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs,), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "vent_env = gym.make(\"Ventilation\")\n",
    "vect_env = make_vec_env(vent_env)\n",
    "vent_model = PPO(\"MlpPolicy\", vent_env, verbose=1)\n",
    "vent_model.learn(total_timesteps=25000)\n",
    "vent_model.save(\"ppo_ventilation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f220f042-19c8-4c15-97b6-bab586ed8215",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "import torch\n",
    "from torch import nn\n",
    "import gymnasium as gym\n",
    "\n",
    "class MinigridFeaturesExtractor(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space: gym.Space, features_dim: int = 512, normalized_image: bool = False) -> None:\n",
    "        super().__init__(observation_space, features_dim)\n",
    "        n_input_channels = observation_space.shape[0]\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(n_input_channels, 16, (2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, (2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, (2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "        # Compute shape by doing one forward pass\n",
    "        with torch.no_grad():\n",
    "            n_flatten = self.cnn(torch.as_tensor(observation_space.sample()[None]).float()).shape[1]\n",
    "\n",
    "        self.linear = nn.Sequential(nn.Linear(n_flatten, features_dim), nn.ReLU())\n",
    "\n",
    "    def forward(self, observations: torch.Tensor) -> torch.Tensor:\n",
    "        return self.linear(self.cnn(observations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9a81903-bb31-4a91-8dd4-99c8e3497a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 600      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 1279     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 600         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 798         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010315164 |\n",
      "|    clip_fraction        | 0.0524      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | -5.06       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.018      |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00519    |\n",
      "|    value_loss           | 2.83e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 600         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 699         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011429197 |\n",
      "|    clip_fraction        | 0.0851      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | -6.95       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00291    |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00755    |\n",
      "|    value_loss           | 3.03e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 600         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 650         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009904394 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | -2.96       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.023      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00899    |\n",
      "|    value_loss           | 3.56e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 600         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 625         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009919168 |\n",
      "|    clip_fraction        | 0.0956      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | -4.28       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00605     |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00771    |\n",
      "|    value_loss           | 4e-05       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 600         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 601         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008794228 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | -3.16       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0192     |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    value_loss           | 2.9e-05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 600         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 592         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007456105 |\n",
      "|    clip_fraction        | 0.0855      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | -3.92       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00121    |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00856    |\n",
      "|    value_loss           | 5.63e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 600         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 588         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010440767 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | -4.14       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00804     |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    value_loss           | 4.83e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 600         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 580         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009554393 |\n",
      "|    clip_fraction        | 0.0971      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | -3.85       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00118    |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    value_loss           | 3.63e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 600         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 574         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011028146 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | -3.69       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0376     |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 3.37e-05    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7f4771f097d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import minigrid\n",
    "from minigrid.wrappers import ImgObsWrapper\n",
    "from stable_baselines3 import PPO\n",
    "import ventilation_env \n",
    "\n",
    "\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=MinigridFeaturesExtractor,\n",
    "    features_extractor_kwargs=dict(features_dim=128),\n",
    ")\n",
    "\n",
    "env = gym.make(\"Ventilation\", render_mode=\"rgb_array\")\n",
    "env = ImgObsWrapper(env)\n",
    "\n",
    "model = PPO(\"CnnPolicy\", env, policy_kwargs=policy_kwargs, verbose=1)\n",
    "model.learn(2e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73787db2-2add-4421-9b0f-721638f441dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"vent_cartpole\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7326edb2-ae88-433c-9f81-63d192cf3ddd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fcdc3f-a30e-411d-b8e0-bacf950201aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f93fbd-df54-4ad6-bb16-dcf012468e32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6958d78f-b905-4c98-8baa-b8c695b7f413",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m obs \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m----> 4\u001b[0m     action, _states \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     obs, rewards, dones, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m      6\u001b[0m     vec_env\u001b[38;5;241m.\u001b[39mrender(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/plantroom-rl-NMgLvuyx-py3.11/lib/python3.11/site-packages/stable_baselines3/common/base_class.py:555\u001b[0m, in \u001b[0;36mBaseAlgorithm.predict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    537\u001b[0m     observation: Union[np\u001b[38;5;241m.\u001b[39mndarray, Dict[\u001b[38;5;28mstr\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    540\u001b[0m     deterministic: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    541\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[np\u001b[38;5;241m.\u001b[39mndarray, Optional[Tuple[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]]]:\n\u001b[1;32m    542\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;124;03m    Get the policy action from an observation (and optional hidden state).\u001b[39;00m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;124;03m    Includes sugar-coating to handle different observations (e.g. normalizing images).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;124;03m        (used in recurrent policies)\u001b[39;00m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 555\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisode_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/plantroom-rl-NMgLvuyx-py3.11/lib/python3.11/site-packages/stable_baselines3/common/policies.py:346\u001b[0m, in \u001b[0;36mBasePolicy.predict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;66;03m# Switch to eval mode (this affects batch norm / dropout)\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_training_mode(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 346\u001b[0m observation, vectorized_env \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobs_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m th\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    349\u001b[0m     actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict(observation, deterministic\u001b[38;5;241m=\u001b[39mdeterministic)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/plantroom-rl-NMgLvuyx-py3.11/lib/python3.11/site-packages/stable_baselines3/common/policies.py:257\u001b[0m, in \u001b[0;36mBaseModel.obs_to_tensor\u001b[0;34m(self, observation)\u001b[0m\n\u001b[1;32m    252\u001b[0m         observation[key] \u001b[38;5;241m=\u001b[39m obs_\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space[key]\u001b[38;5;241m.\u001b[39mshape))\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_image_space(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space):\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;66;03m# Handle the different cases for images\u001b[39;00m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;66;03m# as PyTorch use channel first format\u001b[39;00m\n\u001b[0;32m--> 257\u001b[0m     observation \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_transpose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservation_space\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    260\u001b[0m     observation \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(observation)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/plantroom-rl-NMgLvuyx-py3.11/lib/python3.11/site-packages/stable_baselines3/common/preprocessing.py:84\u001b[0m, in \u001b[0;36mmaybe_transpose\u001b[0;34m(observation, observation_space)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvec_env\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VecTransposeImage\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_image_space(observation_space):\n\u001b[0;32m---> 84\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[43mobservation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m \u001b[38;5;241m==\u001b[39m observation_space\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mor\u001b[39;00m observation\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m==\u001b[39m observation_space\u001b[38;5;241m.\u001b[39mshape):\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;66;03m# Try to re-order the channels\u001b[39;00m\n\u001b[1;32m     86\u001b[0m         transpose_obs \u001b[38;5;241m=\u001b[39m VecTransposeImage\u001b[38;5;241m.\u001b[39mtranspose_image(observation)\n\u001b[1;32m     87\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m transpose_obs\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m observation_space\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mor\u001b[39;00m transpose_obs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m==\u001b[39m observation_space\u001b[38;5;241m.\u001b[39mshape:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "\n",
    "while True:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    vec_env.render(\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a783e44f-a80a-442c-aed0-89148281a824",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium.core import ObservationWrapper\n",
    "from gymnasium.spaces import Box, Dict\n",
    "import numpy as np\n",
    "class ObjObsWrapper(ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        \"\"\"A wrapper that makes image the only observation.\n",
    "        Args:\n",
    "            env: The environment to apply the wrapper\n",
    "        \"\"\"\n",
    "        super().__init__(env)\n",
    "\n",
    "        self.observation_space = Dict(\n",
    "            {\n",
    "                \"image\": env.observation_space.spaces[\"image\"],\n",
    "                \"mission\": Box(low=0.0, high=1.0, shape=(9,), dtype=np.float32),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        self.color_one_hot_dict = {\n",
    "            \"red\": np.array([1.0, 0.0, 0.0, 0.0, 0.0, 0.0]),\n",
    "            \"green\": np.array([0.0, 1.0, 0.0, 0.0, 0.0, 0.0]),\n",
    "            \"blue\": np.array([0.0, 0.0, 1.0, 0.0, 0.0, 0.0]),\n",
    "            \"purple\": np.array([0.0, 0.0, 0.0, 1.0, 0.0, 0.0]),\n",
    "            \"yellow\": np.array([0.0, 0.0, 0.0, 0.0, 1.0, 0.0]),\n",
    "            \"grey\": np.array([0.0, 0.0, 0.0, 0.0, 0.0, 1.0]),\n",
    "        }\n",
    "\n",
    "        self.obj_one_hot_dict = {\n",
    "            \"ball\": np.array([1.0, 0.0, 0.0]),\n",
    "            \"box\": np.array([0.0, 1.0, 0.0]),\n",
    "            \"key\": np.array([0.0, 0.0, 1.0]),\n",
    "        }\n",
    "\n",
    "    def observation(self, obs):\n",
    "        mission_array = np.concatenate(\n",
    "            [\n",
    "                self.color_one_hot_dict[self.target_color],\n",
    "                self.obj_one_hot_dict[self.target_obj],\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        wrapped_obs = {\n",
    "            \"image\": obs[\"image\"],\n",
    "            \"mission\": mission_array,\n",
    "        }\n",
    "\n",
    "        return wrapped_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "863ce8d1-e7d5-41af-b43f-b8078dc4de8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Calculated padded input size per channel: (7 x 7). Kernel size: (8 x 8). Kernel size can't be greater than actual input size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m env \u001b[38;5;241m=\u001b[39m gym\u001b[38;5;241m.\u001b[39mmake(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVentilation\u001b[39m\u001b[38;5;124m\"\u001b[39m, render_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m env \u001b[38;5;241m=\u001b[39m ObjObsWrapper(env)\n\u001b[0;32m----> 4\u001b[0m ppo \u001b[38;5;241m=\u001b[39m \u001b[43mPPO\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMultiInputPolicy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m ppo \u001b[38;5;241m=\u001b[39m ppo\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvent_cartpole.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m, env\u001b[38;5;241m=\u001b[39menv)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/plantroom-rl-NMgLvuyx-py3.11/lib/python3.11/site-packages/stable_baselines3/ppo/ppo.py:164\u001b[0m, in \u001b[0;36mPPO.__init__\u001b[0;34m(self, policy, env, learning_rate, n_steps, batch_size, n_epochs, gamma, gae_lambda, clip_range, clip_range_vf, normalize_advantage, ent_coef, vf_coef, max_grad_norm, use_sde, sde_sample_freq, target_kl, stats_window_size, tensorboard_log, policy_kwargs, verbose, seed, device, _init_setup_model)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_kl \u001b[38;5;241m=\u001b[39m target_kl\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _init_setup_model:\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/plantroom-rl-NMgLvuyx-py3.11/lib/python3.11/site-packages/stable_baselines3/ppo/ppo.py:167\u001b[0m, in \u001b[0;36mPPO._setup_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_setup_model\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 167\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# Initialize schedules for policy/value clipping\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip_range \u001b[38;5;241m=\u001b[39m get_schedule_fn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip_range)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/plantroom-rl-NMgLvuyx-py3.11/lib/python3.11/site-packages/stable_baselines3/common/on_policy_algorithm.py:123\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm._setup_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrollout_buffer \u001b[38;5;241m=\u001b[39m buffer_cls(\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_steps,\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    120\u001b[0m     n_envs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_envs,\n\u001b[1;32m    121\u001b[0m )\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# pytype:disable=not-instantiable\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[assignment]\u001b[39;49;00m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservation_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_schedule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_sde\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_sde\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy_kwargs\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# pytype:enable=not-instantiable\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/plantroom-rl-NMgLvuyx-py3.11/lib/python3.11/site-packages/stable_baselines3/common/policies.py:853\u001b[0m, in \u001b[0;36mMultiInputActorCriticPolicy.__init__\u001b[0;34m(self, observation_space, action_space, lr_schedule, net_arch, activation_fn, ortho_init, use_sde, log_std_init, full_std, use_expln, squash_output, features_extractor_class, features_extractor_kwargs, share_features_extractor, normalize_images, optimizer_class, optimizer_kwargs)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    834\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    835\u001b[0m     observation_space: spaces\u001b[38;5;241m.\u001b[39mDict,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    851\u001b[0m     optimizer_kwargs: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    852\u001b[0m ):\n\u001b[0;32m--> 853\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobservation_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[43maction_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr_schedule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnet_arch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[43mactivation_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m        \u001b[49m\u001b[43mortho_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_sde\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_std_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfull_std\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_expln\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[43msquash_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeatures_extractor_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeatures_extractor_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshare_features_extractor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormalize_images\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/plantroom-rl-NMgLvuyx-py3.11/lib/python3.11/site-packages/stable_baselines3/common/policies.py:481\u001b[0m, in \u001b[0;36mActorCriticPolicy.__init__\u001b[0;34m(self, observation_space, action_space, lr_schedule, net_arch, activation_fn, ortho_init, use_sde, log_std_init, full_std, use_expln, squash_output, features_extractor_class, features_extractor_kwargs, share_features_extractor, normalize_images, optimizer_class, optimizer_kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mortho_init \u001b[38;5;241m=\u001b[39m ortho_init\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_features_extractor \u001b[38;5;241m=\u001b[39m share_features_extractor\n\u001b[0;32m--> 481\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures_extractor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_features_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures_extractor\u001b[38;5;241m.\u001b[39mfeatures_dim\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_features_extractor:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/plantroom-rl-NMgLvuyx-py3.11/lib/python3.11/site-packages/stable_baselines3/common/policies.py:120\u001b[0m, in \u001b[0;36mBaseModel.make_features_extractor\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_features_extractor\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseFeaturesExtractor:\n\u001b[1;32m    119\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Helper method to create a features extractor.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures_extractor_class\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservation_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures_extractor_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/plantroom-rl-NMgLvuyx-py3.11/lib/python3.11/site-packages/stable_baselines3/common/torch_layers.py:261\u001b[0m, in \u001b[0;36mCombinedExtractor.__init__\u001b[0;34m(self, observation_space, cnn_output_dim, normalized_image)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, subspace \u001b[38;5;129;01min\u001b[39;00m observation_space\u001b[38;5;241m.\u001b[39mspaces\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_image_space(subspace, normalized_image\u001b[38;5;241m=\u001b[39mnormalized_image):\n\u001b[0;32m--> 261\u001b[0m         extractors[key] \u001b[38;5;241m=\u001b[39m \u001b[43mNatureCNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcnn_output_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_image\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalized_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m         total_concat_size \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m cnn_output_dim\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    264\u001b[0m         \u001b[38;5;66;03m# The observation key is a vector, flatten it if needed\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/plantroom-rl-NMgLvuyx-py3.11/lib/python3.11/site-packages/stable_baselines3/common/torch_layers.py:101\u001b[0m, in \u001b[0;36mNatureCNN.__init__\u001b[0;34m(self, observation_space, features_dim, normalized_image)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Compute shape by doing one forward pass\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m th\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 101\u001b[0m     n_flatten \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation_space\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(nn\u001b[38;5;241m.\u001b[39mLinear(n_flatten, features_dim), nn\u001b[38;5;241m.\u001b[39mReLU())\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/plantroom-rl-NMgLvuyx-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/plantroom-rl-NMgLvuyx-py3.11/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/plantroom-rl-NMgLvuyx-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/plantroom-rl-NMgLvuyx-py3.11/lib/python3.11/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/plantroom-rl-NMgLvuyx-py3.11/lib/python3.11/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Calculated padded input size per channel: (7 x 7). Kernel size: (8 x 8). Kernel size can't be greater than actual input size"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"Ventilation\", render_mode=\"human\")\n",
    "env = ObjObsWrapper(env)\n",
    "\n",
    "ppo = PPO(\"MultiInputPolicy\", env, verbose=1)\n",
    "ppo = ppo.load(\"vent_cartpole.zip\", env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d0e729-a72a-4914-a67d-64529ac9abea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe8e4ac-cd4a-4a26-b177-3b6944861aff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6907cb-3b71-4fca-8482-f1b3e7f2c358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 22.2     |\n",
      "|    ep_rew_mean     | 22.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 7745     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 8192     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.8        |\n",
      "|    ep_rew_mean          | 32.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3259        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014580395 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.681      |\n",
      "|    explained_variance   | 0.000206    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.77        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0245     |\n",
      "|    value_loss           | 20.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.7        |\n",
      "|    ep_rew_mean          | 77.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2663        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016654426 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.645      |\n",
      "|    explained_variance   | 0.415       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0337     |\n",
      "|    value_loss           | 24.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 107         |\n",
      "|    ep_rew_mean          | 107         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2314        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011926025 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.602      |\n",
      "|    explained_variance   | 0.439       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0262     |\n",
      "|    value_loss           | 38.8        |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Parallel environments\n",
    "vec_env = make_vec_env(\"CartPole-v1\", n_envs=4)\n",
    "\n",
    "model = PPO(\"MlpPolicy\", vec_env, verbose=1)\n",
    "model.learn(total_timesteps=25000)\n",
    "model.save(\"ppo_cartpole\")\n",
    "\n",
    "del model # remove to demonstrate saving and loading\n",
    "\n",
    "model = PPO.load(\"ppo_cartpole\")\n",
    "\n",
    "obs = vec_env.reset()\n",
    "#while True:\n",
    "##    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = vec_env.step(action)\n",
    "    vec_env.render(\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6285ebea-0ffe-4851-8d69-b28519f29087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14485aa6-d732-4d9b-a173-94483d7c7f57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb69fdcf-e809-4887-a51c-6b85c4129aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 22.2     |\n",
      "|    ep_rew_mean     | 22.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 7745     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 8192     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.8        |\n",
      "|    ep_rew_mean          | 32.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3259        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014580395 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.681      |\n",
      "|    explained_variance   | 0.000206    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.77        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0245     |\n",
      "|    value_loss           | 20.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.7        |\n",
      "|    ep_rew_mean          | 77.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2663        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016654426 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.645      |\n",
      "|    explained_variance   | 0.415       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0337     |\n",
      "|    value_loss           | 24.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 107         |\n",
      "|    ep_rew_mean          | 107         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2314        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011926025 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.602      |\n",
      "|    explained_variance   | 0.439       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0262     |\n",
      "|    value_loss           | 38.8        |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Parallel environments\n",
    "vec_env = make_vec_env(\"CartPole-v1\", n_envs=4)\n",
    "\n",
    "model = PPO(\"MlpPolicy\", vec_env, verbose=1)\n",
    "model.learn(total_timesteps=25000)\n",
    "model.save(\"ppo_cartpole\")\n",
    "\n",
    "del model # remove to demonstrate saving and loading\n",
    "\n",
    "model = PPO.load(\"ppo_cartpole\")\n",
    "\n",
    "obs = vec_env.reset()\n",
    "#while True:\n",
    "##    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = vec_env.step(action)\n",
    "    vec_env.render(\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980bce15-afa3-44f3-953f-cc54c538cf89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30ef02b-49f1-4f75-872e-ca037db317e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b4ce6f-5281-434c-b15c-7760a9d3bd80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
